from datetime import datetime
import random as ran
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
import sys

# *****************************************************************************

# constant variables
# learning rate
ALPHA = 0.1
FLUX = 0.15 # percentage value 0-1
ENERGY = 2 # energy units cost per bit
WEIGHTS = 15 # max weight
NODES = 6 # num of nodes in network including sink
MAX_COST = 1000
TRANSMITION_COST = 10
SGD_STEPS = 5
# *****************************************************************************
# array of nodes in network
paths = {3 : "310", 4: "420", 5: "520", 1 : "10", 2 : "20"}
costs = {0: 0, 1: 3, 2: 1, 3: 0.5, 4: 2 , 5:1.5}
# *****************************************************************************
# setup of the neural network model's layers initialisation

class Model_Node(Model):
    # initialise model using the tensorflow recommended layers
    
    grads = []
    num_of_vars = 0
    node_id = None
    
    def __init__(self, nid):
        super(Model_Node, self).__init__()
        self.W = tf.Variable(tf.ones([784, 10]), name="weight")
        self.b = tf.Variable(tf.zeros([10]), name="bias")
        self.num_of_vars = -1
        self.node_id = nid

    def call(self, x):
        return tf.nn.softmax(tf.matmul(x, self.W) + self.b)
    
    def __getitem__(self, item): return self

    # initialising stochastic gradient descent function
    optimizer = tf.keras.optimizers.SGD(learning_rate=ALPHA)

    # setting up the metrics collection tensors
    train_loss = tf.keras.metrics.Mean(name='train_loss'+str(node_id))
    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
        name='train_accuracy'+str(node_id))

    test_loss = tf.keras.metrics.Mean(name='test_loss'+str(node_id))
    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
        name='test_accuracy'+str(node_id))
    
    def loss(self, y_true, y_pred):
        y_true = tf.one_hot(y_true, depth=10)
        y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)
        return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred),1))

    def accuracy(self, y_true, y_pred):
        # Predicted class is the index of highest score in prediction vector (i.e. argmax).
        correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))
        return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    
    # model train function
    @tf.function
    def train_step(self, images, labels, glo=False, g=None):
        # if glo=true then it updates the global model using the gradient
        # given in argument g
        if glo:
            self.optimizer.apply_gradients(zip(g, self.trainable_variables),
                                           experimental_aggregate_gradients=True)
            return
        with tf.GradientTape() as tape:
            predictions = self(images, training=True)
            tloss = self.loss(labels, predictions)
        gradients = tape.gradient(tloss, self.trainable_variables);
        if self.num_of_vars < 0: self.num_of_vars = len(self.trainable_variables)
        # applies training gradients using stochastic gradient descend
        self.optimizer.apply_gradients(zip(gradients,
                                           self.trainable_variables),
                                       experimental_aggregate_gradients=False)
        # calculates loss and accuracy
        self.train_loss(tloss)
        self.train_accuracy(labels, predictions)
        x = self.num_of_vars
        self.grads = gradients[-x:]
        # returns the gradient
        return self.grads

    # model predict function
    @tf.function
    def test_step(self, images, labels):
        # predicts the label
        predictions = self(images, training=False)
        t_loss = self.loss(labels, predictions)
        # calculates loss and accuracy
        self.test_loss(t_loss)
        self.test_accuracy(labels, predictions)

# *****************************************************************************
# function for averaging the gradients
def avgs(matrices = []):
    segmentIDs = [0] * len(matrices)
    return tf.math.segment_mean(matrices, segmentIDs)

# function returning the enegry cost
def compute_transmission_cost(node):
    cost = 0
    for c in paths[node]: cost += (costs[int(c)] * ENERGY)
    return cost
# *****************************************************************************
start_time =  datetime.now().strftime("%H:%M:%S")

# sim run
mnist = tf.keras.datasets.mnist
print("loading dataset...")
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# Converting data to float32
x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)
# Flatten images to 1-D vector of 784 features (28*28).
x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)
# Normalize images value from [0, 255] to [0, 1].
x_train, x_test = x_train / 255., x_test / 255.
train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(5)
test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(5)

init = None
nds = [[], [], [], [], []]
i = 0
for img, lbl in train_ds:
        if i == 0: init = (img, lbl); i += 1; continue
        nds[i%5].append((img, lbl))
        i += 1
print("dataset split")
# *****************************************************************************
print("initialiasing nodes")
nodes = []
for i in range(0, NODES):
    nodes.append(Model_Node(i)); print("node", i, "initialised")
    nodes[-1].train_loss.reset_states()
    nodes[-1].train_accuracy.reset_states()
    nodes[-1].test_loss.reset_states()
    nodes[-1].test_accuracy.reset_states()
# *****************************************************************************
j = 0
ecost = 0
ecosts, acc, los,  bits = [], [], [], []
gs = [[], [], [], [], [], []]
# initial train of all nodes
for i in range(0, NODES):
    nodes[i].train_step(init[0], init[1])
    if i == 0: continue
    nodes[i].set_weights(nodes[0].get_weights())
# main training and testing loop
for i in range(0, len(nds[0])):
    idiv = i % SGD_STEPS
    print("Iteration: ", i)
    # train the local models
    for j in range(1, NODES):
        print("training local model ", j)
        g = nodes[j].train_step(nds[j-1][i][0], nds[j-1][i][1])
        # save gradients in list 
    if idiv == (SGD_STEPS - 1):
        ws = nodes[0].get_weights()
        for j in range(1, NODES): 
            g = nodes[j].get_weights()
            for k in range(0, 2): gs[k].append(g[k])
        for j in range(0, 2):
            for k in range(0, 5): gs[j][k] = ws[j] - gs[j][k]
        for j in range(0, 2): ws[j] = (gs[j][0] + gs[j][1] + gs[j][2]
                                       + gs[j][3] + gs[j][4]) / 5
        nodes[0].optimizer.apply_gradients(zip(ws,nodes[0].trainable_variables),
                                           experimental_aggregate_gradients=True)
        # gather metrics for graphs
        for ti, tl in test_ds: nodes[0].test_step(ti, tl)
        acc.append(nodes[0].test_accuracy.result() * 100)
        los.append(nodes[0].test_loss.result())
        print("Accuracy: ", acc[-1])
        print("Loss: ", los[-1])
        for j in range(1, NODES):
            ct = compute_transmission_cost(j)
            for k in range(0, 2): ecost += (gs[k][j-1].nbytes * 8 * ct)
        ecosts.append(ecost)
        print("Energy cost: ", ecost)
        size = 0
        for g in gs: 
            for w in g: size += w.nbytes * 8
        bits.append(size)
        print("Bits: ", bits[-1])
        gs = [[], [], [], [], [], []]
        for j in range(1, NODES):
            nodes[j].set_weights(nodes[0].get_weights())
        nodes[0].test_loss.reset_states()
        nodes[0].test_accuracy.reset_states()
# run another last iteration to account for the leftover records
print("Iteration: ", i+1)
print("Remainder: ", i % SGD_STEPS)
ws = nodes[0].get_weights()
for j in range(1, NODES): 
    g = nodes[j].get_weights()
    for k in range(0, 2): gs[k].append(g[k])
for j in range(0, 2):
    for k in range(0, 5): gs[j][k] = ws[j] - gs[j][k]
for j in range(0, 2): ws[j] = (gs[j][0] + gs[j][1] + gs[j][2]
                               + gs[j][3] + gs[j][4]) / 5
nodes[0].optimizer.apply_gradients(zip(ws,nodes[0].trainable_variables),
                                   experimental_aggregate_gradients=True)
# gather metrics for graphs
for ti, tl in test_ds: nodes[0].test_step(ti, tl)
acc.append(nodes[0].test_accuracy.result() * 100)
los.append(nodes[0].test_loss.result())
print("Accuracy: ", acc[-1])
print("Loss: ", los[-1])
for j in range(1, NODES):
    ct = compute_transmission_cost(j)
    for k in range(0, 2): ecost += (gs[k][j-1].nbytes * 8 * ct)
ecosts.append(ecost)
print("Energy cost: ", ecost)
size = 0
for g in gs: 
    for w in g: size += w.nbytes * 8
bits.append(size)
print("Bits: ", bits[-1])
# *****************************************************************************
print("script finished running")
print("start time: ", start_time, " --------- end time:",
      datetime.now().strftime("%H:%M:%S"))

