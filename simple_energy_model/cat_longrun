from datetime import datetime
import tensorflow as tf
import numpy as np
from numpy import linalg as la
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
import sys
import random as rand

# *****************************************************************************

# constant variables
ALPHA = 0.1 # learning rate
ENERGY = 2 # energy units cost per bit
NODES = 6 # num of nodes in network including sink
SGD_STEPS = 5 # num of stochastic gradient descent steps in between updates
T_PERCENTAGE = 0.04
# *****************************************************************************
# array of nodes in network
paths = {3 : "310", 4: "420", 5: "520", 1 : "10", 2 : "20"}
costs = {0: 0, 1: 3, 2: 1, 3: 0.5, 4: 2 , 5:1.5}
# *****************************************************************************
# setup of the neural network model's layers initialisation
class Model_Node(Model):
    # initialise model using the tensorflow recommended layers
    
    grads = []
    num_of_vars = 0
    node_id = None

    def __init__(self, nid):
        super(Model_Node, self).__init__()
        self.W = tf.Variable(tf.ones([784, 10]), name="weight")
        self.b = tf.Variable(tf.zeros([10]), name="bias")
        self.num_of_vars = -1
        self.node_id = nid

    def call(self, x):
        return tf.nn.softmax(tf.matmul(x, self.W) + self.b)   
 
    def __getitem__(self, item): return self

    # initialising stochastic gradient descent function
    optimizer = tf.keras.optimizers.SGD(learning_rate=ALPHA)

    # setting up the metrics collection tensors
    train_loss = tf.keras.metrics.Mean(name='train_loss'+str(node_id))
    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
        name='train_accuracy'+str(node_id))

    test_loss = tf.keras.metrics.Mean(name='test_loss'+str(node_id))
    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
        name='test_accuracy'+str(node_id))

    def loss(self, y_true, y_pred):
        y_true = tf.one_hot(y_true, depth=10)
        y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)
        return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred),1))


    def accuracy(self, y_true, y_pred):
        correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))
        return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    
    # model train function
    @tf.function
    def train_step(self, images, labels, glo=False, g=None):
        # if glo=true then it updates the global model using the gradient
        # given in argument g
        if glo:
            self.optimizer.apply_gradients(zip(g, self.trainable_variables),
                                           experimental_aggregate_gradients=True)
            return
        with tf.GradientTape() as tape:
            predictions = self(images, training=True)
            tloss = self.loss(labels, predictions)
        gradients = tape.gradient(tloss, self.trainable_variables);
        if self.num_of_vars < 0: self.num_of_vars = len(self.trainable_variables)
        # applies training gradients using stochastic gradient descend
        self.optimizer.apply_gradients(zip(gradients,
                                           self.trainable_variables),
                                       experimental_aggregate_gradients=False)
        # calculates loss and accuracy
        self.train_loss(tloss)
        self.train_accuracy(labels, predictions)
        x = self.num_of_vars
        self.grads = gradients[-x:]
        # returns the gradient
        return self.grads

    # model predict function
    @tf.function
    def test_step(self, images, labels):
        # predicts the label
        predictions = self(images, training=False)
        t_loss = self.loss(labels, predictions)
        # calculates loss and accuracy
        self.test_loss(t_loss)
        self.test_accuracy(labels, predictions)

# *****************************************************************************
# function for averaging the gradients
def avgs(matrices = []):
    segmentIDs = [0] * len(matrices)
    return tf.math.segment_mean(matrices, segmentIDs)

# function returning the enegry cost
def compute_transmission_cost(node):
    cost = 0
    for c in paths[node]: cost += (costs[int(c)] * ENERGY)
    return cost
# *****************************************************************************
start_time =  datetime.now().strftime("%H:%M:%S")

# sim run
mnist = tf.keras.datasets.mnist
print("loading dataset...")
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# Converting data to float32
x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)
# Flatten images to 1-D vector of 784 features (28*28).
x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)
# Normalize images value from [0, 255] to [0, 1].
x_train, x_test = x_train / 255., x_test / 255.
train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(5)
test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(5)

init = None
nds = [[], [], [], [], []]
i = 0
for img, lbl in train_ds:
        if i == 0: init = (img, lbl); i += 1
        for j in range(0, 5):
            nds[j].append((img, lbl))
            nds[j].append((img, lbl))
            nds[j].append((img, lbl))
for i in range(0, 5): rand.shuffle(nds[i])
print("dataset split")
# *****************************************************************************
print("initialiasing nodes")
nodes = []
for i in range(0, NODES):
    nodes.append(Model_Node(i)); print("node", i, "initialised")
    nodes[-1].train_loss.reset_states()
    nodes[-1].train_accuracy.reset_states()
    nodes[-1].test_loss.reset_states()
    nodes[-1].test_accuracy.reset_states()
# *****************************************************************************
j, ecost = 0, 0
ecosts, acc, los, bits = [], [], [], []
gs = []
# initial train of all nodes
for i in range(0, NODES):
    nodes[i].train_step(init[0], init[1])
    if i == 0: continue
    nodes[i].set_weights(nodes[0].get_weights())
gsizes = []
totg = 0 #total number of gradients in model
for g in nodes[0].get_weights(): gsizes.append(g.size); totg += g.size
maxg = int(T_PERCENTAGE * totg) # number of max values to send
# main training and testing loop
for i in range(0, len(nds[0])):
    print("Iteration: ", i)
    # train the local models
    for j in range(1, NODES):
        print("training local model ", j)
        g = nodes[j].train_step(nds[j-1][i][0], nds[j-1][i][1])
    idiv = i % SGD_STEPS # checks how many steps of SGD have been run
    if idiv == (SGD_STEPS - 1):
        ws = nodes[0].get_weights()
        nd = [0] * (NODES - 1)
        # t-compress gradient (client side)
        for j in range(1, NODES):
            print("Starting gradient compression for node", j, "at",
                  datetime.now().strftime("%H:%M:%S"))
            g = nodes[j].get_weights()
            totsize, size = 0, 0
            for k in range(0, 2): g[k] = ws[k] - g[k]
            gflat = np.concatenate(g, axis=None)
            totsize = gflat.nbytes
            inds = np.argsort(abs(gflat))
            cc = compute_transmission_cost(j) * 8
            minval, minind = 0, 0
            for k in range(1, len(inds)+1):
                compressed = gflat[inds[-k:]]
                calc = (la.norm(compressed)**2) / (la.norm(gflat)**2)
                calc /= (cc * compressed.size)
                if calc > minval: minval = calc; minind = k; continue
                if calc < minval: break
            size = np.array(inds[-minind:]).nbytes + np.array(
                gflat[inds[-minind:]]).nbytes
            gs.append([inds[-minind:], gflat[inds[-minind:]]])
            percentage = (size / totsize) * 100
            nd[j-1] = size
            print("Node ", j, ": compressed and sent ",
                  percentage, "% of original gradient using", k-1, "gradients")
            print("Compression finished at", datetime.now().strftime("%H:%M:%S"))
        # average differences (server side)
        for j in range(0, 2): ws[j] = np.zeros(ws[j].shape, dtype="float32")
        d = {}
        for e in gs:
            for gi, gv in zip(e[0], e[1]): d.setdefault(gi, []).append(gv)
        for gi, gv in d.items():
            for k in range(0, 2):
                if gi < gsizes[k]:
                    ws[k][np.unravel_index(gi, ws[k].shape)] = np.mean(gv)
                    break
                gi -= gsizes[k]
        # update global model
        nodes[0].optimizer.apply_gradients(zip(ws,nodes[0].trainable_variables),
                                           experimental_aggregate_gradients=True)
        # gather metrics for graphs
        for ti, tl in test_ds: nodes[0].test_step(ti, tl)
        acc.append(nodes[0].test_accuracy.result() * 100)
        los.append(nodes[0].test_loss.result())
        print("Accuracy: ", acc[-1])
        print("Loss:", los[-1])
        for j in range(1, NODES):
            ct = compute_transmission_cost(j)
            ecost += ct * nd[j-1] * 8
        ecosts.append(ecost)
        print("Energy cost: ", ecost)
        size = 0
        for n in nd: size += n * 8
        bits.append(size)
        print("Bits: ", bits[-1])
        gs = []
        for j in range(1, NODES): nodes[j].set_weights(nodes[0].get_weights())
        nodes[0].test_loss.reset_states()
        nodes[0].test_accuracy.reset_states()

# *****************************************************************************
print("script finished running")
print("start time: ", start_time, " --------- end time:",
      datetime.now().strftime("%H:%M:%S"))

